{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XLyU2Y60KRbk",
    "outputId": "61e14c48-7adc-4f77-9eff-6a9ed5c2341b"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "09yydkSeKsC6",
    "outputId": "d6ec79d7-d4a8-4cd5-de3e-f8edf3b55faf"
   },
   "outputs": [],
   "source": [
    "# # prompt: take me to the RA Data folder\n",
    "\n",
    "# %cd /content/drive/MyDrive/RA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "KRAKBzIhJexF"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchsummary import summary\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0mfBMJzDJexG"
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(in_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "WKRbjDniJexH"
   },
   "outputs": [],
   "source": [
    "# class DualTaskResNet(nn.Module):\n",
    "#     def __init__(self, num_classes=1, pretrained=True):\n",
    "#         super(DualTaskResNet, self).__init__()\n",
    "#         # Load a pretrained ResNet\n",
    "#         self.resnet = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "\n",
    "#         # Remove the last fully connected layer\n",
    "#         self.features = nn.Sequential(*list(self.resnet.children())[:-2])\n",
    "\n",
    "#         # Upsampling layers for mask generation\n",
    "#         self.upsample1 = self._make_upsample_block(2048, 1024)\n",
    "#         self.upsample2 = self._make_upsample_block(1024, 512)\n",
    "#         self.upsample3 = self._make_upsample_block(512, 256)\n",
    "#         self.upsample4 = self._make_upsample_block(256, 64)\n",
    "#         self.upsample5 = self._make_upsample_block(64, num_classes, final=True)\n",
    "\n",
    "#         # Enhanced skeletonization layers\n",
    "#         self.skeleton_decoder = nn.Sequential(\n",
    "#             nn.Conv2d(num_classes, 32, kernel_size=3, padding=1),\n",
    "#             nn.BatchNorm2d(32),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             ResidualBlock(32),\n",
    "#             nn.Conv2d(32, 16, kernel_size=3, padding=1),\n",
    "#             nn.BatchNorm2d(16),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             ResidualBlock(16),\n",
    "#             nn.Conv2d(16, num_classes, kernel_size=1)\n",
    "#         )\n",
    "\n",
    "#     def _make_upsample_block(self, in_channels, out_channels, final=False):\n",
    "#         layers = []\n",
    "#         for i in range(3):  # Stack 3 ConvTranspose2d layers\n",
    "#             if i == 0:\n",
    "#                 layers.append(nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2))\n",
    "#             else:\n",
    "#                 layers.append(nn.ConvTranspose2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1))\n",
    "#             if not final:\n",
    "#                 layers.append(nn.BatchNorm2d(out_channels))\n",
    "#                 layers.append(nn.ReLU(inplace=True))\n",
    "#         return nn.Sequential(*layers)\n",
    "\n",
    "#     def forward(self, x, task='mask'):\n",
    "#         x = self.features(x)\n",
    "#         x = self.upsample1(x)\n",
    "#         x = self.upsample2(x)\n",
    "#         x = self.upsample3(x)\n",
    "#         x = self.upsample4(x)\n",
    "#         mask = self.upsample5(x)\n",
    "\n",
    "#         if task == 'mask':\n",
    "#             return torch.sigmoid(mask)\n",
    "#         elif task == 'skeleton':\n",
    "#             skeleton = self.skeleton_decoder(mask)\n",
    "#             return torch.sigmoid(skeleton)\n",
    "\n",
    "#     def freeze_encoder(self):\n",
    "#         for param in self.features.parameters():\n",
    "#             param.requires_grad = False\n",
    "\n",
    "#     def unfreeze_encoder(self):\n",
    "#         for param in self.features.parameters():\n",
    "#             param.requires_grad = True\n",
    "\n",
    "#     def freeze_decoder(self):\n",
    "#         for layer in [self.upsample1, self.upsample2, self.upsample3, self.upsample4, self.upsample5]:\n",
    "#             for param in layer.parameters():\n",
    "#                 param.requires_grad = False\n",
    "\n",
    "#     def unfreeze_decoder(self):\n",
    "#         for layer in [self.upsample1, self.upsample2, self.upsample3, self.upsample4, self.upsample5]:\n",
    "#             for param in layer.parameters():\n",
    "#                 param.requires_grad = True\n",
    "\n",
    "#     def finetune_for_skeleton(self):\n",
    "#         # Freeze the encoder and decoder\n",
    "#         self.freeze_encoder()\n",
    "#         self.freeze_decoder()\n",
    "\n",
    "#         # Unfreeze only the skeleton decoder\n",
    "#         for param in self.skeleton_decoder.parameters():\n",
    "#             param.requires_grad = True\n",
    "\n",
    "#     def prepare_for_full_training(self):\n",
    "#         # Unfreeze all layers for full training\n",
    "#         self.unfreeze_encoder()\n",
    "#         self.unfreeze_decoder()\n",
    "#         for param in self.skeleton_decoder.parameters():\n",
    "#             param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "iSNQSiyfyIst"
   },
   "outputs": [],
   "source": [
    "class DualTaskResNet(nn.Module):\n",
    "    def __init__(self, num_classes=1, pretrained=True):\n",
    "        super(DualTaskResNet, self).__init__()\n",
    "        \n",
    "        resnet = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1 if pretrained else None)\n",
    "        self.resnet18 = nn.Sequential(*list(resnet.children())[:-2])\n",
    "        self.layer0 = nn.Sequential(*list(self.resnet18.children())[:3])\n",
    "        self.layer1 = nn.Sequential(*list(self.resnet18.children())[3:5])\n",
    "        self.layer2 = self.resnet18[5]\n",
    "        self.layer3 = self.resnet18[6]\n",
    "        self.layer4 = self.resnet18[7]\n",
    "\n",
    "        # Dilated convolutions for layer2\n",
    "        self.dilation_conv1 = self._make_dilated_conv(128, 256, 2)\n",
    "        self.dilation_conv2 = self._make_dilated_conv(128, 256, 4)\n",
    "        self.dilation_conv3 = self._make_dilated_conv(128, 256, 8)\n",
    "        self.dilation_conv4 = self._make_dilated_conv(128, 256, 16)\n",
    "        self.dilation_conv5 = self._make_dilated_conv(128, 256, 32)\n",
    "\n",
    "        # Dilated convolutions for layer3\n",
    "        self.dilation_conv6 = self._make_dilated_conv(256, 512, 2)\n",
    "        self.dilation_conv7 = self._make_dilated_conv(256, 512, 4)\n",
    "        self.dilation_conv8 = self._make_dilated_conv(256, 512, 8)\n",
    "        self.dilation_conv9 = self._make_dilated_conv(256, 512, 16)\n",
    "        self.dilation_conv10 = self._make_dilated_conv(256, 512, 32)\n",
    "\n",
    "        # Upsampling path\n",
    "        self.upsample1 = self._make_transpose_conv(512, 512, 2)  # 7x7 -> 14x14\n",
    "        self.upsample2 = self._make_transpose_conv(3072, 512, 2)  # 14x14 -> 28x28\n",
    "        self.upsample3 = self._make_transpose_conv(1792, 256, 2)  # 28x28 -> 56x56\n",
    "        self.upsample4 = self._make_transpose_conv(256, 128, 2)  # 56x56 -> 112x112\n",
    "        self.upsample5 = self._make_transpose_conv(128, 64, 2)  # 112x112 -> 224x224\n",
    "        self.convf = nn.Conv2d(64, num_classes, kernel_size=1)\n",
    "\n",
    "        # Task-specific output layers\n",
    "        self.mask_output = nn.Conv2d(num_classes, num_classes, kernel_size=1)\n",
    "        self.skeleton_output = nn.Conv2d(num_classes, num_classes, kernel_size=1)\n",
    "\n",
    "    def _make_dilated_conv(self, in_channels, out_channels, dilation):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=dilation, dilation=dilation),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def _make_transpose_conv(self, in_channels, out_channels, scale_factor):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=scale_factor, padding=0, output_padding=0),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, img, task='mask'):\n",
    "        # Expected input size: 224x224x3\n",
    "        layer0 = self.layer0(img)  # 112x112x64\n",
    "        layer1 = self.layer1(layer0)  # 56x56x64\n",
    "        layer2 = self.layer2(layer1)  # 28x28x128\n",
    "        layer3 = self.layer3(layer2)  # 14x14x256\n",
    "        layer4 = self.layer4(layer3)  # 7x7x512\n",
    "\n",
    "        # Apply dilation to layer2 (28x28x128)\n",
    "        y1 = self.dilation_conv1(layer2)\n",
    "        y2 = self.dilation_conv2(layer2)\n",
    "        y3 = self.dilation_conv3(layer2)\n",
    "        y4 = self.dilation_conv4(layer2)\n",
    "        y5 = self.dilation_conv5(layer2)\n",
    "        y = torch.cat([y1, y2, y3, y4, y5], dim=1)  # 28x28x1280\n",
    "\n",
    "        # Apply dilation to layer3 (14x14x256)\n",
    "        z1 = self.dilation_conv6(layer3)\n",
    "        z2 = self.dilation_conv7(layer3)\n",
    "        z3 = self.dilation_conv8(layer3)\n",
    "        z4 = self.dilation_conv9(layer3)\n",
    "        z5 = self.dilation_conv10(layer3)\n",
    "        z = torch.cat([z1, z2, z3, z4, z5], dim=1)  # 14x14x2560\n",
    "\n",
    "        # Upsampling path\n",
    "        x = self.upsample1(layer4)  # 14x14x512\n",
    "        x = torch.cat([x, z], dim=1)  # 14x14x3072\n",
    "        x = self.upsample2(x)  # 28x28x512\n",
    "        x = torch.cat([x, y], dim=1)  # 28x28x1792\n",
    "        x = self.upsample3(x)  # 56x56x256\n",
    "        x = self.upsample4(x)  # 112x112x128\n",
    "        x = self.upsample5(x)  # 224x224x64\n",
    "        x = self.convf(x)  # 224x224xnum_classes\n",
    "\n",
    "        if task == 'mask':\n",
    "            output = self.mask_output(x)\n",
    "        elif task == 'skeleton':\n",
    "            output = self.skeleton_output(x)\n",
    "        else:\n",
    "            raise ValueError(\"Task must be either 'mask' or 'skeleton'\")\n",
    "\n",
    "        return torch.sigmoid(output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jz1KFBQVJexI"
   },
   "outputs": [],
   "source": [
    "# Test function\n",
    "def test_dualtask_resnet():\n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Create model instance\n",
    "    model = DualTaskResNet(num_classes=1, pretrained=False).to(device)\n",
    "\n",
    "    # Print model summary\n",
    "    summary(model, (3, 224, 224))\n",
    "\n",
    "    # Generate random input\n",
    "    batch_size = 4\n",
    "    input_tensor = torch.randn(batch_size, 3, 224, 224).to(device)\n",
    "\n",
    "    # Test mask generation\n",
    "    print(\"\\nTesting mask generation:\")\n",
    "    mask_output = model(input_tensor, task='mask')\n",
    "    print(f\"Mask output shape: {mask_output.shape}\")\n",
    "    print(f\"Mask output min: {mask_output.min().item():.4f}, max: {mask_output.max().item():.4f}\")\n",
    "\n",
    "    # Test skeletonization\n",
    "    print(\"\\nTesting skeletonization:\")\n",
    "    skeleton_output = model(input_tensor, task='skeleton')\n",
    "    print(f\"Skeleton output shape: {skeleton_output.shape}\")\n",
    "    print(f\"Skeleton output min: {skeleton_output.min().item():.4f}, max: {skeleton_output.max().item():.4f}\")\n",
    "\n",
    "    # Test if outputs are different\n",
    "    print(\"\\nChecking if mask and skeleton outputs are different:\")\n",
    "    is_different = not torch.allclose(mask_output, skeleton_output)\n",
    "    print(f\"Outputs are different: {is_different}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZnDzZCBrJexI",
    "outputId": "f03ac0b9-d05c-4bc6-a6fc-8b82de942f93"
   },
   "outputs": [],
   "source": [
    "# test_dualtask_resnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "2nxlB692JexJ"
   },
   "outputs": [],
   "source": [
    "class DualTaskDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, skeleton_dir, image_transform=None, mask_transform=None):\n",
    "        self.image_dir = os.path.normpath(image_dir)\n",
    "        self.mask_dir = os.path.normpath(mask_dir)\n",
    "        self.skeleton_dir = os.path.normpath(skeleton_dir)\n",
    "        self.image_transform = image_transform\n",
    "        self.mask_transform = mask_transform\n",
    "        self.image_files = [f for f in os.listdir(self.image_dir) if f.endswith('.jpeg') or f.endswith('.jpg') or f.endswith('.png')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.normpath(os.path.join(self.image_dir, img_name))\n",
    "\n",
    "        # Construct the mask and skeleton paths\n",
    "        base_name = os.path.splitext(img_name)[0]\n",
    "        mask_name = base_name + '.png'\n",
    "        skeleton_name = base_name + '.png'\n",
    "        mask_path = os.path.normpath(os.path.join(self.mask_dir, mask_name))\n",
    "        skeleton_path = os.path.normpath(os.path.join(self.skeleton_dir, skeleton_name))\n",
    "\n",
    "        # Load the images\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        mask = Image.open(mask_path).convert('L')\n",
    "        skeleton = Image.open(skeleton_path).convert('L')\n",
    "\n",
    "        # Apply transforms\n",
    "        if self.image_transform:\n",
    "            image = self.image_transform(image)\n",
    "        if self.mask_transform:\n",
    "            mask = self.mask_transform(mask)\n",
    "            skeleton = self.mask_transform(skeleton)\n",
    "\n",
    "        return image, mask, skeleton, img_name  # Return the image name as well\n",
    "\n",
    "\n",
    "def get_data_loaders(image_dir, mask_dir, skeleton_dir, batch_size=32, train_split=0.8, val_split=0.1, test_split=0.1):\n",
    "    # Define transforms for input images\n",
    "    image_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5514, 0.4094, 0.3140], std=[0.1299, 0.1085, 0.0914])\n",
    "    ])\n",
    "\n",
    "    # Define transforms for masks and skeletons\n",
    "    mask_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    # Create dataset\n",
    "    full_dataset = DualTaskDataset(image_dir, mask_dir, skeleton_dir,\n",
    "                                   image_transform=image_transform,\n",
    "                                   mask_transform=mask_transform)\n",
    "\n",
    "    # Calculate split sizes\n",
    "    total_size = len(full_dataset)\n",
    "    train_size = int(train_split * total_size)\n",
    "    val_size = int(val_split * total_size)\n",
    "    test_size = total_size - train_size - val_size\n",
    "\n",
    "    # Split the dataset\n",
    "    train_dataset, val_dataset, test_dataset = random_split(full_dataset, [train_size, val_size, test_size])\n",
    "\n",
    "    # Optimize DataLoader\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "                              # num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "                            # num_workers=1, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "                             # num_workers=1, pin_memory=True)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OCr9zTeVJexJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "I5okkVn2JexJ"
   },
   "outputs": [],
   "source": [
    "def linear_loss_decay(epoch, total_epochs, start_weight=0.5, end_weight=1.0):\n",
    "    return start_weight + (end_weight - start_weight) * (epoch / total_epochs)\n",
    "\n",
    "def calculate_iou(pred, target, threshold=0.5):\n",
    "    pred = (pred > threshold).float()\n",
    "    intersection = (pred * target).sum()\n",
    "    union = pred.sum() + target.sum() - intersection\n",
    "    return (intersection + 1e-6) / (union + 1e-6)  # Adding small epsilon to avoid division by zero\n",
    "\n",
    "def calculate_pos_weight(train_loader):\n",
    "    total_pixels = 0\n",
    "    skeleton_pixels = 0\n",
    "    for _, _, skeletons, _ in tqdm(train_loader, desc=\"Calculating pos_weight\"):\n",
    "        total_pixels += skeletons.numel()\n",
    "        skeleton_pixels += skeletons.sum().item()\n",
    "    neg_pos_ratio = (total_pixels - skeleton_pixels) / skeleton_pixels\n",
    "    return torch.tensor([neg_pos_ratio])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "QWYq2G1IJexJ"
   },
   "outputs": [],
   "source": [
    "def validate(model, val_loader, criterion, device, task):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    iou_sum = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, masks, skeletons, _ in val_loader:\n",
    "            images = images.to(device)\n",
    "            targets = masks.to(device) if task == 'mask' else skeletons.to(device)\n",
    "\n",
    "            outputs = model(images, task=task)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            iou_sum += calculate_iou(outputs, targets)\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_iou = iou_sum / len(val_loader)\n",
    "\n",
    "    return val_loss, val_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedDiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1., beta=0.5):\n",
    "        super(WeightedDiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "        self.beta = beta  # Weight for the foreground class\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        pred = torch.sigmoid(pred)\n",
    "        pred = pred.view(-1)\n",
    "        target = target.view(-1)\n",
    "\n",
    "        # Calculate weights\n",
    "        w_fg = self.beta\n",
    "        w_bg = 1 - self.beta\n",
    "\n",
    "        # Weighted intersection and union\n",
    "        intersection = (pred * target * w_fg).sum()\n",
    "        union = (pred * w_fg).sum() + (target * w_fg).sum()\n",
    "\n",
    "        # Add background contribution\n",
    "        intersection += ((1 - pred) * (1 - target) * w_bg).sum()\n",
    "        union += ((1 - pred) * w_bg).sum() + ((1 - target) * w_bg).sum()\n",
    "\n",
    "        dice = (2. * intersection + self.smooth) / (union + self.smooth)\n",
    "        return 1 - dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4989425539970398\n"
     ]
    }
   ],
   "source": [
    "# Check\n",
    "criterion = WeightedDiceLoss(beta=0.7)  # Adjust beta based on your dataset's imbalance\n",
    "pred = torch.randn(1, 1, 224, 224)  # Example prediction\n",
    "target = torch.randint(0, 2, (1, 1, 224, 224))  # Example target mask\n",
    "loss = criterion(pred, target)\n",
    "print(f\"Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true,
    "id": "KX7oTHNxJexK",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_mask_model(model, train_loader, val_loader, num_epochs, device, beta=0.7, validate_every=10):\n",
    "    best_mask_iou = 0.0\n",
    "    best_mask_model_weights = None\n",
    "    mask_train_losses, mask_val_losses, mask_ious, mask_lrs = [], [], [], []\n",
    "\n",
    "    criterion_mask = WeightedDiceLoss(beta=beta)\n",
    "    optimizer_mask = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    constant_lr_epochs = num_epochs // 2\n",
    "    cosine_annealing_epochs = num_epochs - constant_lr_epochs\n",
    "\n",
    "    scheduler_mask = torch.optim.lr_scheduler.LambdaLR(optimizer_mask, lambda epoch: 1)  # Constant LR\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        pbar = tqdm(train_loader, desc=f\"Mask Training Epoch {epoch+1}/{num_epochs}\")\n",
    "        for images, masks, _, _ in pbar:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "            optimizer_mask.zero_grad()\n",
    "            outputs_mask = model(images, task='mask')\n",
    "            loss = criterion_mask(outputs_mask, masks)\n",
    "            loss.backward()\n",
    "            optimizer_mask.step()\n",
    "\n",
    "            train_loss += loss.item() * images.size(0)\n",
    "            \n",
    "            pbar.set_postfix({\n",
    "                'Train Loss': f'{loss.item():.4f}',\n",
    "                'LR': f'{scheduler_mask.get_last_lr()[0]:.6f}'\n",
    "            })\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        mask_train_losses.append(train_loss)\n",
    "        mask_lrs.append(scheduler_mask.get_last_lr()[0])\n",
    "\n",
    "        # Validate every 10 epochs\n",
    "        if (epoch + 1) % validate_every == 0:\n",
    "            val_loss, mask_iou = validate(model, val_loader, criterion_mask, device, task='mask')\n",
    "            mask_val_losses.append(val_loss)\n",
    "            mask_ious.append(mask_iou)\n",
    "            \n",
    "            print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, '\n",
    "                  f'Val Loss: {val_loss:.4f}, Mask IoU: {mask_iou:.4f}')\n",
    "            \n",
    "            if mask_iou > best_mask_iou:\n",
    "                best_mask_iou = mask_iou\n",
    "                best_mask_model_weights = model.state_dict().copy()\n",
    "                print(f'New best mask model saved with IoU: {best_mask_iou:.4f}')\n",
    "\n",
    "        if epoch == constant_lr_epochs - 1:\n",
    "            scheduler_mask = CosineAnnealingLR(optimizer_mask, T_max=cosine_annealing_epochs)\n",
    "        \n",
    "        scheduler_mask.step()\n",
    "\n",
    "    visualization_data = {\n",
    "        'train_losses': mask_train_losses,\n",
    "        'val_losses': mask_val_losses,\n",
    "        'ious': mask_ious,\n",
    "        'lrs': mask_lrs\n",
    "    }\n",
    "\n",
    "    return model, best_mask_model_weights, visualization_data\n",
    "\n",
    "def finetune_skeleton_model(model, train_loader, val_loader, num_epochs, device, best_mask_model_path):\n",
    "    # Load the best mask model\n",
    "    state_dict = torch.load(best_mask_model_path, map_location=device)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.to(device)\n",
    "    \n",
    "    best_skeleton_iou = 0.0\n",
    "    best_skeleton_model_weights = None\n",
    "    skeleton_train_losses, skeleton_val_losses, skeleton_ious, skeleton_lrs = [], [], [], []\n",
    "\n",
    "    pos_weight = calculate_pos_weight(train_loader)\n",
    "    criterion_skeleton = nn.BCEWithLogitsLoss(pos_weight=pos_weight.to(device))\n",
    "    optimizer_skeleton = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    constant_lr_epochs = num_epochs // 2\n",
    "    cosine_annealing_epochs = num_epochs - constant_lr_epochs\n",
    "    scheduler_skeleton = torch.optim.lr_scheduler.LambdaLR(optimizer_skeleton, lambda epoch: 1)  # Constant LR\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        pbar = tqdm(train_loader, desc=f\"Skeleton Finetuning Epoch {epoch+1}/{num_epochs}\")\n",
    "        for batch in pbar:\n",
    "            images, _, skeletons, _ = batch  # Unpack correctly regardless of the number of items\n",
    "            images, skeletons = images.to(device), skeletons.to(device)\n",
    "\n",
    "            optimizer_skeleton.zero_grad()\n",
    "            outputs_skeleton = model(images, task='skeleton')\n",
    "            loss = criterion_skeleton(outputs_skeleton, skeletons)\n",
    "            loss.backward()\n",
    "            optimizer_skeleton.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            pbar.set_postfix({\n",
    "                'Train Loss': f'{loss.item():.4f}',\n",
    "                'LR': f'{scheduler_skeleton.get_last_lr()[0]:.6f}'\n",
    "            })\n",
    "        \n",
    "        scheduler_skeleton.step()  # Step the scheduler once per epoch\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        skeleton_train_losses.append(train_loss)\n",
    "        skeleton_lrs.append(scheduler_skeleton.get_last_lr()[0])\n",
    "\n",
    "        # Validation at the end of each epoch\n",
    "        val_loss, skeleton_iou = validate(model, val_loader, criterion_skeleton, device, task='skeleton')\n",
    "        skeleton_val_losses.append(val_loss)\n",
    "        skeleton_ious.append(skeleton_iou)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, '\n",
    "              f'Val Loss: {val_loss:.4f}, Skeleton IoU: {skeleton_iou:.4f}')\n",
    "        \n",
    "        if skeleton_iou > best_skeleton_iou:\n",
    "            best_skeleton_iou = skeleton_iou\n",
    "            best_skeleton_model_weights = model.state_dict().copy()\n",
    "            print(f'New best skeleton model saved with IoU: {best_skeleton_iou:.4f}')\n",
    "\n",
    "        if epoch == constant_lr_epochs - 1:\n",
    "            scheduler_skeleton = CosineAnnealingLR(optimizer_skeleton, T_max=cosine_annealing_epochs)\n",
    "\n",
    "    visualization_data = {\n",
    "        'train_losses': skeleton_train_losses,\n",
    "        'val_losses': skeleton_val_losses,\n",
    "        'ious': skeleton_ious,\n",
    "        'lrs': skeleton_lrs\n",
    "    }\n",
    "\n",
    "    return model, best_skeleton_model_weights, visualization_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "9hl6ZW5pJexK",
    "outputId": "6b35a058-c17b-4f7d-bcd6-eb066dc79db8",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "7Bne5dbfJexK",
    "outputId": "5affd140-2163-4792-bbdc-aa7f00050189",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 1: Training mask model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mask Training Epoch 1/100: 100%|██████████| 19/19 [11:36<00:00, 36.63s/it, Train Loss=0.5862, LR=0.001000]\n",
      "Mask Training Epoch 2/100: 100%|██████████| 19/19 [11:49<00:00, 37.33s/it, Train Loss=0.6001, LR=0.001000]\n",
      "Mask Training Epoch 3/100:   5%|▌         | 1/19 [00:35<10:32, 35.13s/it, Train Loss=0.6117, LR=0.001000]"
     ]
    }
   ],
   "source": [
    "image_dir = \"DATA/IMG\"\n",
    "mask_dir = \"DATA/MASK\"\n",
    "skeleton_dir = \"DATA/SKELETON\"\n",
    "batch_size = 32\n",
    "\n",
    "train_loader, val_loader, test_loader = get_data_loaders(image_dir, mask_dir, skeleton_dir, batch_size)\n",
    "\n",
    "model = DualTaskResNet(num_classes=1, pretrained=True)\n",
    "model.to(device)\n",
    "\n",
    "# Phase 1: Train mask model\n",
    "print(\"Phase 1: Training mask model\")\n",
    "model, best_mask_weights, mask_vis_data = train_mask_model(\n",
    "    model, train_loader, val_loader, num_epochs=100, device=device, beta=0.7\n",
    ")\n",
    "\n",
    "# Save the best mask model\n",
    "torch.save(best_mask_weights, 'best_mask_model.pth')\n",
    "print(\"Best mask model saved.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 2: Finetune skeleton model\n",
    "print(\"Phase 2: Finetuning skeleton model\")\n",
    "model, best_skeleton_weights, skeleton_vis_data = finetune_skeleton_model(\n",
    "    model, train_loader, val_loader, num_epochs=100, device=device, best_mask_model_path='best_mask_model.pth'\n",
    ")\n",
    "\n",
    "\n",
    "# Save the best skeleton model\n",
    "torch.save(best_skeleton_weights, 'best_skeleton_model.pth')\n",
    "print(\"Best skeleton model saved.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine visualization data\n",
    "vis_data = {\n",
    "    'mask': mask_vis_data,\n",
    "    'skeleton': skeleton_vis_data\n",
    "}\n",
    "\n",
    "print(\"Training completed and best models saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "id": "bt8q2clLJexL",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_training(visualization_data):\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(20, 12))\n",
    "    fig.suptitle('Training and Validation Metrics', fontsize=16)\n",
    "\n",
    "    phases = ['mask', 'skeleton']\n",
    "    colors = ['blue', 'red']\n",
    "\n",
    "    for i, phase in enumerate(phases):\n",
    "        # Plot training and validation loss\n",
    "        axs[i, 0].plot(visualization_data[phase]['train_losses'], label='Train Loss', color=colors[0])\n",
    "        axs[i, 0].plot(visualization_data[phase]['val_losses'], label='Val Loss', color=colors[1])\n",
    "        axs[i, 0].set_title(f'{phase.capitalize()} Loss')\n",
    "        axs[i, 0].set_xlabel('Epoch')\n",
    "        axs[i, 0].set_ylabel('Loss')\n",
    "        axs[i, 0].legend()\n",
    "\n",
    "        # Plot IoU\n",
    "        axs[i, 1].plot(visualization_data[phase]['ious'], label='IoU', color=colors[0])\n",
    "        axs[i, 1].set_title(f'{phase.capitalize()} IoU')\n",
    "        axs[i, 1].set_xlabel('Epoch')\n",
    "        axs[i, 1].set_ylabel('IoU')\n",
    "        axs[i, 1].legend()\n",
    "\n",
    "        # Plot Learning Rate\n",
    "        axs[i, 2].plot(visualization_data[phase]['lrs'], label='Learning Rate', color=colors[0])\n",
    "        axs[i, 2].set_title(f'{phase.capitalize()} Learning Rate')\n",
    "        axs[i, 2].set_xlabel('Epoch')\n",
    "        axs[i, 2].set_ylabel('Learning Rate')\n",
    "        axs[i, 2].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "id": "0lESS3OPJexL",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visulize Training\n",
    "visualize_training(vis_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "id": "sjTaecfuJexL",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_loader_for_test = test_loader\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss, test_mask_iou, test_skeleton_iou, test_avg_iou = validate(trained_model, test_loader, criterion, device)\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Mask IoU: {test_mask_iou:.4f}, '\n",
    "        f'Test Skeleton IoU: {test_skeleton_iou:.4f}, Test Avg IoU: {test_avg_iou:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "id": "wc_vbqUXJexL",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generate_skeletons(model, test_dataloader, save_dir, device='cuda'):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    os.makedirs(save_dir, exist_ok=True)  # Ensure the save directory exists\n",
    "\n",
    "    with torch.no_grad():  # No need to compute gradients for inference\n",
    "        for batch in tqdm(test_dataloader, desc=\"Generating Skeletons\"):\n",
    "            # Unpack the batch\n",
    "            images, _, _, img_names = batch\n",
    "            images = images.to(device)\n",
    "\n",
    "            # Generate skeleton predictions\n",
    "            skeleton_preds = model(images, task='skeleton')\n",
    "\n",
    "            # Apply a threshold to get binary skeletons\n",
    "            skeleton_binary = (skeleton_preds > 0.3).float()\n",
    "\n",
    "            # Save each predicted skeleton\n",
    "            for j, img_name in enumerate(img_names):\n",
    "                # Use the original image name for the skeleton file\n",
    "                base_name = os.path.splitext(img_name)[0]\n",
    "                save_path = os.path.join(save_dir, f\"{base_name}_skeleton.png\")\n",
    "                save_image(skeleton_binary[j], save_path)\n",
    "                print(f\"Skeleton saved at: {save_path}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "id": "Bi4wwGaSJexL",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load your trained model\n",
    "model = DualTaskResNet(num_classes=1, pretrained=False)  # Adjust num_classes if necessary\n",
    "model.load_state_dict(torch.load(\"best_skeleton_model.pth\"))  # Load the trained weights\n",
    "model = model.to('cuda')  # Send the model to the GPU (or use 'cpu')\n",
    "\n",
    "# Load your test dataloader (assumes test_dataloader is defined)\n",
    "# Example: test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Directory where skeletons will be saved\n",
    "save_dir = \"./skeleton_predictions\"\n",
    "\n",
    "# Call the skeleton generation function\n",
    "generate_skeletons(model, test_loader, save_dir, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CWu8eZ-KJexL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LYD6NJAGVOvP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
